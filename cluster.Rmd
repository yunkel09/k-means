---
title: k-means
subtitle: Ejercicio Obligatorio
author:
- name: William Chavarría
  affiliation: Máxima Formación
  email: wchavarria@tigo.com.gt
date: '`r format(Sys.Date())`'
output: 
  bookdown::html_document2:
    toc: true
    toc_float: true
    highlight: pygments
    theme: spacelab
    css: custom_cluster.css
    fig_caption: true
    df_print: paged
bibliography: [paquetes_cluster.bib, cluster.bib]
biblio-style: "apalike"
link-citations: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo        = TRUE, 
                      include     = TRUE,
                      cache       = FALSE,
                      fig.align   = 'center',
                      message     = FALSE,
                      warning     = FALSE, 
                      comment     = NA, 
                      highlight   = TRUE,
                      strip.white = TRUE,
                      dev         = "svglite",
                      fig.width   = 8,
                      fig.asp     = 0.618,
                      fig.show    = "hold",
                      fig.align   = "center")
```

# Mall {.tabset .tabset-fade .tabset-pills}

## Descripción

Realiza una segmentación de clientes de un centro comercial en función de sus
características y consumo. El objetivo principal de este ejercicio es comprender
a los clientes y separarlos en diferentes grupos según sus preferencias. Una vez
realizada la división se puede dar esta información al equipo de marketing para
que puedan planificar la estrategia en consecuencia.

Utiliza los datos Mall customer de Kaggle, que fueron recogidos a través de las
tarjetas de membresía, y tienen algunos datos básicos sobre sus clientes.


Los datos contienen información sobre 200 clientes para las siguientes variables:  

- ID identificador único asignado al cliente  

- Sexo del cliente  

- Edad del cliente  

- Ingresos anuales del cliente (k$)   

- Puntuación de gasto (1-100). 

La puntuación de gasto es asignada por el centro comercial según el
comportamiento del cliente y los datos de compra.


Realiza un análisis cluster de **partición** con el algoritmo de kmedias,
utilizando las distintas técnicas que hemos visto en el temario:

1. Selección y exploración de los datos, Análisis de tendencia de la agrupación,
2. Elección del número óptimo de grupos,
3. Representación e interpretación de los grupos,
4. Importancia de las variables y
5. Validación

Recuerda SOLO incluir variables numéricas en el análisis cluster por k-medias.

## Paquetes

```{r}
options(warn = -1,
		  scipen = 999,
		  dplyr.summarise.inform = FALSE,
		  tibble.print_min = 5,
		  pillar.sigfig = 4,
		  readr.show_col_types = FALSE)
```

```{r}
conserje <- c("tabyl",
				  "make_clean_names",
              "adorn_pct_formatting",
              "adorn_totals",
              "make_clean_names")
```


```{r}
import::from("janitor", conserje, .character_only = TRUE)
import::from(statistigo, coloring_font)
import::from(skimr, skim)
import::from(GGally, ggpairs, wrap)
import::from(clustertend, hopkins)
import::from(factoextra, fviz_dist, fviz_cluster)
import::from(NbClust, NbClust)
import::from(clValid, clValid, optimalScores)
import::from(scales, percent_format)
import::from(formattable, color_tile)
import::from(fpc, cluster.stats)
# import::from(parallel, detectCores, makePSOCKcluster, stopCluster)
# import::from(tidytext, reorder_within, scale_y_reordered, scale_x_reordered)
# import::from(doParallel, registerDoParallel)
import::from(cowplot, .except = "stamp")
import::from(kableExtra, .except = "group_rows")
# import::from(magrittr, "%T>%", "%$%", .into = "operadores")
import::from(DataExplorer, plot_intro, plot_bar, plot_density)
import::from(conectigo, cargar_fuentes)
import::from(colorblindr, scale_fill_OkabeIto)
pacman::p_load(cluster, FeatureImpCluster, flexclust, tidymodels, tidyverse)
```

## Funciones

```{r}
tabla <- function(df, cap = "prueba") {
  
  df %>% 
   kbl(booktabs = TRUE, caption = cap, escape = F) %>% 
   kable_paper(lightable_options = "hover", full_width = F)}
```

```{r}
resaltar <- function(texto) {
    
    glue::glue("<span style='background-color: #FFFF00'>**{texto}**</span>")
    
}
```

```{r}
rlt <- function(texto, color) {
    
	a <- "<span style='background-color: "
	b <- "'>"
	c <- "</span>"
	t <- str_c("**", texto, "**")
	f <- str_c(a, color, b)
	glue::glue(f, t, c) 
	
}
```

```{r}
colort <- function(vec, colorv, paleta, usarv = T) {
	
	# show_col(viridis_pal(option = "turbo")(30))
	# paleta solo pueden ser A (magma), B (inferno), C (plasma),
	# D (viridis) y E(cividis)
	# rojo:     #F4354D
	# amarillo: #FCA108
	# verde:    #00AB40
	if (usarv == T) {
		
		cell_spec(vec,
				 color = "white",
				 bold = TRUE,
				 background = spec_color(x = colorv, 
				 								option = paleta, 
				 								direction = 1))
	} else {
		
		cell_spec(vec,
				 color = "white",
				 bold = TRUE,
				 background = colorv)
	}
	
	
}
```

```{r}
unregister <- function() {
  env <- foreach:::.foreachGlobals
  rm(list = ls(name = env), pos = env)
}
```

```{r}
# agregar línea loess a las gráficas ggpairs
loess_lm <- function(data, mapping, ...){
 
ggplot(data = data, mapping = mapping) + 
    geom_point(alpha = 0.9) + 
    stat_smooth(formula = y ~ x, 
                method = "lm", 
                se = TRUE, 
                color = "blue",
                fill = "blue",
                size = 0.5, 
                alpha = 0.2,
                linetype = "longdash", 
                ...)
}
```

## Opciones

```{r}
set.seed(2021)
```

```{r}
colorx <- c(rojo = "#F4354D", amarillo = "#FCA108", verde = "#00AB40")
```


```{r}
cargar_fuentes()
```

```{r}
yunkel <- theme_cowplot(font_family = "yano") +
	       theme(plot.margin = unit(c(3, 1, 1, 1), "mm"), 
	             axis.title = element_text(size = 12))
```

```{r}
# tema con grid horizontal y vertical
drako <- theme_bw(base_family = "yano", base_size = 14) +
	      theme(plot.margin = unit(c(6, 1, 1, 1), "mm"),
	            axis.title = element_text(size = 12),
	            plot.subtitle = element_text(size = 8,
                                            family = "sans"))
```

```{r}
theme_set(drako)
```

# Carga

Cargar los datos y transformar aquellas variables que se consideren factor.

```{r, eval = FALSE, include = FALSE}
# correr interactivo
ruta <- fs::path("07_clusters_pca", "mall", ext = "csv")
mall <- read_csv(file        = ruta, 
					  name_repair = make_clean_names, 
					  lazy        = TRUE, 
					  col_names   = c("id", "gender", "age", "income", "score"),
					  col_types   = "ifiii",
					  skip        = 1)
```


```{r}
mall <- read_csv(file        = "mall.csv", 
				name_repair = make_clean_names, 
				lazy        = TRUE, 
				col_names   = c("id", "gender", "age", "income", "score"),
				col_types   = "ifiii",
				skip        = 1)
```


# Análisis Exploratorio

```{r, paged.print = FALSE}
slice_sample(mall, n = 3)
```

```{r}
plot_intro(mall, ggtheme = yunkel)
```

<br/>

Ninguna de nuestras variables tiene datos ausentes. Solo hay una variable
categórica.

```{r, paged.print = FALSE}
summary(mall)
```

- Vemos que la variable `r coloring_font("**gender**", "#93330E")` presenta un
desbalance con 112 casos para Female y 88 casos para Male. 

- Las variables están medidas en unidades distintas.

(ref:pairs) Seleccionar y visualizar los datos

```{r pairs, fig.cap ='(ref:pairs)', fig.width = 10, fig.asp = 0.6}
mall %>%
	select(gender:score) %>% 
	ggpairs(., aes(colour = gender), 
			  lower = list(continuous = loess_lm),
 		     upper = list(continuous = wrap("cor", size = 5))) + 
	scale_fill_OkabeIto() +
	drako
```

<br/>

En el gráfico \@ref(fig:pairs) observamos:

1. La mediana de edad entre hombres y mujeres es bastante similar, siendo los
los hombres el grupo más disperso. El diagrama de densidad indica que hay una
pequeña bimodalidad en el grupo de las mujeres.  No se observa una relación
clara entre el ingreso y el género. Con respecto a la relación entre la edad
y la puntuación se ve relación negativa en la que pareciera que una mayor edad
se traduce en una menor puntuación.

2. El `r coloring_font("**income**", "#93330E")` es bastante similar. Se observa
que hay un valor atípico en el ingreso de los hombres. Probablemente el ingreso
de uno de los clientes se sale del rango. La distribución es bastante similar
en cuanto a diagrama de densidad.  Algo interesante es ver como hay un grupo de
ingresos en torno a los USD50K que parecen obtener una puntuación similar de 50.

3. La mediana de `r coloring_font("**score**", "#93330E")` es prácticamente la
misma para hombres y hombres, con un poco más de dispersión para hombres.

# Estandarizar

```{r}
mall_std <- scale(mall[-c(1:2)])
mall_dis <- dist(mall_std)
```

```{r}
summary(mall_std)
```

Ahora tenemos las variables numéricas con un rango de valores similar.

# Tendencia de agrupación

## Hopkins

Primero se debe evaluar si con los datos seleccionados es conveniente agrupar.

```{r}
set.seed(2021)
hopkins(mall_std, n = nrow(mall_std) - 1)
```

Podemos concluir que los datos si muestran una tendencia de agrupación debido
a que el valor es distinto a 0.5.

## VAT

(ref:vat) Evaluación visual de tendencia

```{r vat, fig.cap ='(ref:vat)', fig.width = 9, fig.asp = 0.6}
fviz_dist(mall_dis, lab_size = .1, show_labels = F)
```

<br/>

Aquí vemos que los datos si tienen cierta tendencia de agrupación, con lo cual
tiene sentido continuar con su análisis. 

# Número óptimo de grupos

Evaluemos la cantidad óptima de grupos con base a los siguientes criterios:

## Calidad interna

```{r, echo = FALSE}
set.seed(2021)
nclu <- NbClust(mall_std, method = "kmeans", min.nc = 2, max.nc = 10)
```

Vemos que **5 de los estadísticos proponen crear únicamente 2 grupos.**

## Estabilidad

```{r}
mall_std %>% 
	clValid(nClust     = 2:10,
	        clMethods  = "kmeans",
	        validation = "stability") %>% 
	optimalScores()
```

**2 de los estadísticos proponen formar 2 grupos.**

# Aplicar k-means

```{r}
mall_km <- kmeans(mall_std, centers = 2, nstart = 10)
```

Al agregar el argumento `nstart` en la función `kmeans()` limita el problema de
la estabilidad en los resultados, ya que generará varias inicializaciones
diferentes y tomará la más óptima, lo que conducirá a una mejor estabilidad de
la clasificación.


# Representación e interpretación


```{r}
mall %>% 
	bind_cols(cluster = mall_km$cluster) %>% 
	slice_sample(n = 3)
```

Aquí podemos ver en que cluster se clasificó a cada individuo.

Ahora, con la función `tidy()` podemos resumir las características principales
de cada grupo

```{r, tb}
tidy(mall_km)
```

<br/>

- **Cardinalidad:** Los grupos tienen un tamaño bastante homogéneo con una
diferencia de solo 6 observaciones entre ellos.

- **Variabilidad intra-grupo** (*withinss*): El grupo 1 es el más variable,
pudiendo significar que las observaciones dentro de cada grupo no son tan
homogéneas u uniformes.

- **Centroides:** Vemos los valores medios de cada variable en cada grupo.
Debido a que están escaladas obtenemos valores centrados en cero.

	- **Edad:** El grupo 2 tiene más edad.
	- **Ingresos:** El grupo 2 tiene ligeramente más ingresos con valores muy
	cercanos a la media.
	- **Puntuación:** El grupo 2 tiene una mayor puntuación.

- **Grupos:**

```{r}
mall %>% 
	bind_cols(cluster = mall_km$cluster) %>% 
	select(-id) %>% 
   group_by(cluster) %>% 
	summarise(across(where(is.numeric), mean)) %>% 
	mutate(
		cluster = as.factor(cluster),
		across(is.numeric, ~ color_tile("#fd625e", "#91CF60")(.x)),
	) %>% tabla("Resumen")
```

<br/>

El grupo 1 destaca por edad y el grupo 2 destaca puntuación.

Con `augment()` podemos agregar las clasificaciones de puntos al conjunto de
datos original.

(ref:aumento) Ingresos contra edad

```{r, aumento, fig.cap ='(ref:aumento)', fig.width = 8, fig.asp = 0.6}
augment(mall_km, mall_std) %>% 
	ggplot(aes(age, income, color = .cluster)) +
	geom_point() + drako
```

Podemos aumentar los resultados de la agrupación con nuestros datos originales y
de esta forma podemos trazar cualquiera de las dimensiones de nuestro espacio,
como la edad y el ingreso. En el gráfico \@ref(fig:aumento) se observa que
realmente hay grupos separables.

Con `glance()` podemos ver el resumen, pero más importante, podemos evaluar
la calidad de la partición.

```{r}
inq <- glance(mall_km) %>%
	mutate(calidad = percent_format(accuracy = 0.01)(betweenss / totss))
```

```{r, tb-02}
inq %>% 
	mutate(quality = colort(calidad, usarv = F, colorv = colorx[1])) %>% 
	select(-calidad) %>% 
	tabla(cap = "Calidad de la partición")
```

<br/>

En la tabla \@ref(tab:tb-02) vemos que la calidad es del
`r inq$calidad`.  Este valor no tiene una interpretación real en términos
absolutos, excepto que una mayor calidad significa un mayor porcentaje
explicado, sin embargo, es más esclarecedor cuando se compara con la calidad de
otras particiones con el mismo número de clústeres.

Esta es la razón por la que comparamos particiones a través de su calidad solo
para particiones que tienen la misma cantidad de clústeres.

```{r}
cl_kcca <- as.kcca(mall_km, mall_std)
barplot(cl_kcca)
```

- El grupo 1 tiene mayores valores para edad y los menores valores para el score
de compra.

- El grupo 2 lo opuesto, mayores valores de score y menores valores de edad.

```{r}
barplot(cl_kcca, bycluster = FALSE)
```

Vamos a visualizar todas las variables de manera conjunta (la función utiliza un
PCA y colorea los grupos formados). Aquí he agregado etiquetas según la
agrupación previa de las observaciones para hacer una comparación visual.

```{r}
fviz_cluster(mall_km, mall_std, 
             labelsize = 8,
             main = "k = 2 grupos",
             geom = "point") + 
  geom_text(label = paste(mall$gender, 1:nrow(mall), sep="_"),  size = 2.5,
            colour = c("darkgreen","blue", "red")[mall$gender]) +
	drako
```

<br/>

Vemos que existen algunas observaciones mal clasificadas, ya que hay mujeres en
el grupo de hombre y viceversa.

# Importancia de las variables

```{r}
importance <- FeatureImpCluster(cl_kcca, as.data.table(mall_std))
plot(importance)
```

<br/>

- La variable más importante es score, pero solo marginalmente con respecto a la
edad, ya que score tiene 0.325 y edad 0.305.

- El grupo 2 es el que tiene mayor score, mientras que el 1 es el que tiene
menores puntuaciones de esta variable.

- El grupo 1 es el que registró mayor edad.

# Validación

```{r}
sk <- silhouette(mall_km$cluster, mall_dis) # gráfico de silueta
plot(sk, main = "Silhouette plot - Kmeans",
cex.names=0.8, col=1:2, nmax=100)
```

<br/>

- El primer grupo tiene un valor de silueta medio de 0.30 y el segundo grupo con
97 observaciones tiene una silueta de 0.37

- El valor de promedio de ancho de silueta es bajo.

- En ambos grupos nos encontramos con observaciones por debajo de 0.25 (punto de
corte) lo cual podría indicar que no están bien agrupados.

Veamos si las observaciones han sido clasificadas correctamente.

```{r}
table(mall$gender, mall_km$cluster)
```

- Tenemos que el grupo 1 contiene 55 observaciones female y 48 observaciones
male.

- Los grupos no son del todo completos ni homogéneos.

Calculamos el índice de Rand ajustado que mide el acuerdo de la agrupación con
la clasificación previa. Toma valores en [-1, 1]; donde -1 es sin acuerdo y 1 un
acuerdo perfecto.

```{r}
rand <- cluster.stats(d = mall_dis, alt.clustering = as.numeric(mall$gender),
                      clustering=as.numeric(mall_km$cluster))
```

```{r}
rand$corrected.rand
```

**La agrupación es mala**

# Conclusión

La agrupación utilizando 2 grupos no fué buena. En la tabla de validación
externa vemos que las mujeres se repartieron casi equitativamente entre ambos
grupos.

La variable más importante fue el score, pero solo ligeramente por encima de la
edad.
